{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dee653e-51ff-4a76-b4f1-135e8d19a3eb",
   "metadata": {},
   "source": [
    "# 1. Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2a2bd4a-ecdf-4a16-85c3-43a49ad14799",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sensor_msgs'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m#from directory_tree import display_tree\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Customed Library\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;241m,\u001b[39m\u001b[38;5;21;01mmodel_builder\u001b[39;00m\u001b[38;5;241m,\u001b[39m\u001b[38;5;21;01mutils\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdata_loader\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m#import torchinfo\u001b[39;00m\n",
      "File \u001b[1;32m~\\Fraunhofer\\Machine_learning\\data_loader.py:10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstatistics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mros_data_reader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Vector_set\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mdata_loader\u001b[39;00m:\n\u001b[0;32m     12\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;124;03m    Mainly Go and look at the folder and file list\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n",
      "File \u001b[1;32m~\\Fraunhofer\\Machine_learning\\ros_data_reader.py:8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# ROS imports\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msensor_msgs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmsg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m JointState\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mur_msgs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmsg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IOStates\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstd_msgs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmsg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Int16MultiArray, Float64, Float32MultiArray\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sensor_msgs'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import sklearn.preprocessing\n",
    "#from directory_tree import display_tree\n",
    "# Customed Library\n",
    "import engine ,model_builder,utils\n",
    "import data_loader\n",
    "import numpy as np\n",
    "#import torchinfo\n",
    "from timeit import default_timer as timer \n",
    "from ros_data_reader import Vector_set\n",
    "#display_tree('./')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b30fa8-0827-4d1f-b401-6e0d1b9388bb",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2. Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae69201c-74ee-4d26-87c1-5c4b880bd8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path='./rosbag_dir'\n",
    "#Desired_param=[[0],[0],[0],[0],[0,1,2]]\n",
    "#New_Columns=['Par1','Par2','Par3','Par4','Par5']\n",
    "\n",
    "path='./first_trial'\n",
    "Desired_param=[[0],[0]]\n",
    "New_Columns=['Par1','Par2']\n",
    "\n",
    "A=data_loader.data_loader(path,Desired_param)\n",
    "A.file_searching(path)\n",
    "list_file=A.desired_file_path(Desired_param)\n",
    "Columns=['Force_X','Force_Y','Force_Z','Torque_X','Torque_Y','Torque_Z',\n",
    "         'Input_P_1','Input_P_2','Flag',\n",
    "         'Sensor_P_1_1','Sensor_P_1_2','Sensor_P_2_1','Sensor_P_2_2',\n",
    "         'Sensor_P_3_1','Sensor_P_3_2','Sensor_P_4_1','Sensor_P_4_2',\n",
    "         'Sensor_P_5_1','Sensor_P_5_2','Sensor_P_6_1','Sensor_P_6_2',\n",
    "         'Sensor_S']\n",
    "Total_dataset=A.read_Data_pandas(Columns,New_Columns)\n",
    "Total_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23aed4c3-0946-4b50-b6c8-1ecc96134c3c",
   "metadata": {},
   "source": [
    "### 3-1. FIltering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35eedcfc-fa2d-48b0-855a-842229e31c1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Data filtering\n",
    "# https://builtin.com/data-science/pandas-filter\n",
    "Filtered_dataset=Total_dataset.query('Flag==True')\n",
    "Filtered_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27cce36",
   "metadata": {},
   "outputs": [],
   "source": [
    "Total_dataset[S_Sensor_col].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6014276c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Fol_col=Total_dataset.columns[:3]\n",
    "Input_P_col=Total_dataset.columns[6:8]\n",
    "Flag_col=Total_dataset.columns[8]\n",
    "P_Sensor_col=Total_dataset.columns[9:21]\n",
    "S_Sensor_col=Total_dataset.columns[21]\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(nrows=4, ncols=1)\n",
    "\n",
    "Total_dataset[Fol_col].plot(ax=axes[0])\n",
    "Total_dataset[Input_P_col].plot(ax=axes[1])\n",
    "Total_dataset[S_Sensor_col].plot(ax=axes[2])\n",
    "Total_dataset[P_Sensor_col].plot(ax=axes[3])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cd41fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Total_dataset.to_pickle(\"./pickle/trial.pkl\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42474ab8-94a5-4310-b77e-13243819e309",
   "metadata": {},
   "source": [
    "### 3-2 Combination of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4973fd3a-ad3c-4285-b638-a1a8ea5833d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Total_col=[*Columns,*New_Columns]\n",
    "for i in range(len(Total_col)):\n",
    "    if i==0:\n",
    "        print(f'{\"Total column\" :^120}')\n",
    "        print('')\n",
    "    print(f'{i:<} {Total_col[i] : <30}   ',end='')\n",
    "    if i%3 ==0 and i!=0:\n",
    "        print('')\n",
    "        \n",
    "\n",
    "Desired_combination_COL=[*Total_col[0:3],*Total_col[-9:-5]] ####################### chose the combination of the col\n",
    "print('')\n",
    "for i in range(len(Desired_combination_COL)):\n",
    "    if i==0:\n",
    "        print(f'{\"Desired_combination_COL\" :^120}')\n",
    "        print('')\n",
    "    print(f'{i:<} {Desired_combination_COL[i] : <30}   ',end='')\n",
    "    if i%3 ==0 and i!=0:\n",
    "        print('')\n",
    "\n",
    "\n",
    "Desired_combination_COL\n",
    "Combi_df=Filtered_dataset.filter(items=Desired_combination_COL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722020a9-f6d8-4186-9d94-63929e8f29de",
   "metadata": {},
   "source": [
    "### 3. Save the file into pickle format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ca7c3f-1543-4765-ae69-5e9adf0880b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_mode= True\n",
    "\n",
    "if save_mode== True:\n",
    "    Combi_df.to_pickle(\"./pickle/test_1.pkl\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63731dee-ee59-44f5-b5f5-6b9609b14804",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 3.Start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f76ac4-bf8e-49c6-9ee2-ade3d8e6bb2c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3-1. Data loading and preparation\n",
    "1) Read pickle\n",
    "2) Divide Input and output && Train and test set\n",
    "3) To Tensor\n",
    "4) Normalization\n",
    "5) Batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3ebee90-cd49-4f8c-af8c-ab25c094095f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 17\u001b[0m\n\u001b[0;32m     10\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m#!nvidia-smi\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Hot encoding needed\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Scailing!\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Validation dataset?\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m Y_t\u001b[38;5;241m=\u001b[39m\u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39marray(Combi_df\u001b[38;5;241m.\u001b[39mfilter(items\u001b[38;5;241m=\u001b[39mDesired_combination_COL[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m3\u001b[39m]))\n\u001b[0;32m     18\u001b[0m X_t\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marray(Combi_df\u001b[38;5;241m.\u001b[39mfilter(items\u001b[38;5;241m=\u001b[39mDesired_combination_COL[\u001b[38;5;241m3\u001b[39m:]))\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Scaler\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "Combi_df = pd.read_pickle(\"./pickle/test_1.pkl\")  \n",
    "\n",
    "\n",
    "# Setup hyperparameters\n",
    "NUM_EPOCHS = 5\n",
    "BATCH_SIZE = 32\n",
    "HIDDEN_UNITS = 10\n",
    "LEARNING_RATE = 0.001\n",
    "#device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = \"cpu\"\n",
    "#!nvidia-smi\n",
    "\n",
    "# Hot encoding needed\n",
    "# Scailing!\n",
    "# Validation dataset?\n",
    "\n",
    "Y_t=np.array(Combi_df.filter(items=Desired_combination_COL[0:3]))\n",
    "X_t=np.array(Combi_df.filter(items=Desired_combination_COL[3:]))\n",
    "\n",
    "# Scaler\n",
    "X_scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "Y_scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "\n",
    "X=torch.FloatTensor(X_scaler.fit_transform(X_t))\n",
    "Y=torch.FloatTensor(Y_scaler.fit_transform(Y_t))\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, \n",
    "                                                    Y, \n",
    "                                                    test_size=0.2, # 20% test, 80% train\n",
    "                                                    random_state=42) # make the random split reproducible\n",
    "\n",
    "\n",
    "train_dataset=DataLoader(data_loader.Data(X_train,Y_train),batch_size=BATCH_SIZE)\n",
    "test_dataset=DataLoader(data_loader.Data(X_test,Y_test),batch_size=BATCH_SIZE)\n",
    "Input_dim=len(X_train[0])\n",
    "Output_dim=len(Y_train[0])\n",
    "\n",
    "print(f'{\"Input dim \":>20}{Input_dim}{\"||\":^25}{\"Output dim \":>20}{Output_dim}')\n",
    "print(f'Input Train: {len(X_train)},Test: {len(X_test)}   ||   Output Train: {len(Y_train)}, Test: {len(Y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deaa31a6-8617-44de-8a48-c135d23794de",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3-2. Set hypermeter\n",
    "1. Epochs\n",
    "2. Batch size\n",
    "3. Learning rate\n",
    "4. Device \n",
    "5. Activation function\n",
    "6. Loss function\n",
    "7. Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c73737",
   "metadata": {},
   "outputs": [],
   "source": [
    "Input_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c22e15-be49-4f93-95b7-a71d7916d133",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Model\n",
    "\n",
    "model = model_builder.LSTMModel1(\n",
    "    input_dim = Input_dim,\n",
    "    hidden_dim=HIDDEN_UNITS,\n",
    "    layer_dim=2,\n",
    "    output_dim=Output_dim,\n",
    "    dropout_prob=0.7)\n",
    "\n",
    "\n",
    "# Set loss and optimizer\n",
    "loss_fn = torch.nn.MSELoss() ## change\n",
    "optimizer = torch.optim.Adam(model.parameters(), ## change\n",
    "                             lr=LEARNING_RATE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea742f3-2160-49f0-bb8d-b317d4b9ccdf",
   "metadata": {},
   "source": [
    "### 3-3. Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f5ff68-c51c-4636-8b4b-529c89eb1e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#torchinfo.summary(model,(5,5,5))\n",
    "start_time = timer()\n",
    "results=engine.train(model=model,\n",
    "             train_dataloader=train_dataset,\n",
    "             test_dataloader=test_dataset,\n",
    "             loss_fn=loss_fn,\n",
    "             optimizer=optimizer,\n",
    "             epochs=NUM_EPOCHS,\n",
    "             device=device)\n",
    "end_time = timer()\n",
    "print(f\"Total training time: {end_time-start_time:.3f} seconds\")\n",
    "utils.plot_loss_curves([results])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb71e1ce-8e4d-43e9-a3eb-7b9d5cb7d9ba",
   "metadata": {},
   "source": [
    "### 3-4 Compare the results and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc31c89-2256-4a59-b9e7-8e8aa5156d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61801e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
